If you update code in github, refreash github...
explanation of the process:
Let‚Äôs go through everything you wrote and explain what it is and why it exists ‚Äî piece by piece.
I‚Äôll group it into:
    1. App code (Sanic app)
    2. Packaging (requirements.txt + Dockerfile)
    3. Local testing (docker build/run)
    4. Git + GitHub
    5. DockerHub
    6. EC2 setup
    7. Deployment script on EC2
    8. GitHub Secrets
    9. GitHub Actions CI/CD workflow
    10. Test & verify

1Ô∏è‚É£ app.py ‚Äì Your Web Application
from sanic import Sanic
from sanic.response import json

app = Sanic("MySanicApp")
    ‚Ä¢ from sanic import Sanic
Imports the Sanic application class ‚Äì it‚Äôs like Flask(__name__) in Flask.
    ‚Ä¢ from sanic.response import json
Imports a helper function to return JSON HTTP responses.
    ‚Ä¢ app = Sanic("MySanicApp")
Creates a Sanic app instance with the name "MySanicApp".
This app object is what defines routes and runs the server.

@app.get("/")
async def index(request):
    return json({"message": "Hello from Sanic + Docker + EC2"})
    ‚Ä¢ @app.get("/")
This is a route decorator. It tells Sanic:
        ‚ó¶ When a GET request comes to / (root URL),
        ‚ó¶ run the index function.
    ‚Ä¢ async def index(request):
Sanic is async, so handlers are async.
        ‚ó¶ request contains info about the HTTP request (headers, params, etc.).
    ‚Ä¢ return json({...})
Sends a JSON response to the client:
      {"message": "Hello from Sanic + Docker + EC2"}
      This is your main success proof when someone hits the API.

@app.get("/health")
async def health(request):
    return json({"status": "ok", "version": "1.0.0"})
    ‚Ä¢ Another endpoint: /health
    ‚Ä¢ Purpose:
        ‚ó¶ Check if app is alive and healthy.
        ‚ó¶ Can be used by monitoring tools or load balancers.
    ‚Ä¢ Returning:
      {"status": "ok", "version": "1.0.0"}
      This is a simple healthcheck API ‚Äì very common in real systems.

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=False)
    ‚Ä¢ This block only runs when you do python app.py directly.
    ‚Ä¢ host="0.0.0.0" ‚Üí accept incoming traffic from any IP, not just localhost
(important for Docker + EC2).
    ‚Ä¢ port=8000 ‚Üí app listens on port 8000.
    ‚Ä¢ debug=False ‚Üí production-like mode, no debug reloader.
Why this whole file?
This is your business logic / application. Everything else (Docker, Git, CI/CD) is just to package and deploy this.

2Ô∏è‚É£ requirements.txt ‚Äì Tell Python What to Install
sanic==23.12.0
    ‚Ä¢ This tells pip which Python packages are needed.
    ‚Ä¢ Exact version is pinned so that:
        ‚ó¶ Local machine, Docker container, and EC2 all use same version.
        ‚ó¶ Avoid ‚Äúworks on my machine, fails in container‚Äù problems.
Why?
Docker image needs to know which dependencies to install during build.

3Ô∏è‚É£ Dockerfile ‚Äì How to Build the Container Image
FROM python:3.11-slim
    ‚Ä¢ Base image = official Python 3.11 slim version.
    ‚Ä¢ ‚Äúslim‚Äù ‚Üí smaller image ‚Üí faster pulls & builds.

WORKDIR /app
    ‚Ä¢ Sets working directory inside the container to /app.
    ‚Ä¢ All subsequent commands (COPY, RUN, CMD) will run from here.
    ‚Ä¢ This is like cd /app inside the container.

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
    ‚Ä¢ COPY requirements.txt .
Copies only requirements.txt from your computer into /app inside the container.
    ‚Ä¢ RUN pip install --no-cache-dir -r requirements.txt
Installs all dependencies inside the image.
We copy requirements.txt first so that Docker can cache this layer:
If only app.py changes but requirements.txt is same, Docker reuses this part.

COPY . .
    ‚Ä¢ Copies all remaining project files (app.py, etc.) into /app in the image.
So now the container has:
    ‚Ä¢ /app/app.py
    ‚Ä¢ /app/requirements.txt
    ‚Ä¢ etc.

EXPOSE 8000
    ‚Ä¢ Documentation for Docker / tools: this container listens on port 8000.
    ‚Ä¢ Not a firewall; your docker run -p 8000:8000 actually exposes it.

CMD ["python", "app.py"]
    ‚Ä¢ This tells Docker:
When this container starts, run:
      python app.py
    ‚Ä¢ That starts the Sanic server inside the container.
Why the whole Dockerfile?
It defines a repeatable, portable environment so the same app runs the same way:
    ‚Ä¢ On your laptop
    ‚Ä¢ On EC2
    ‚Ä¢ Anywhere Docker runs

4Ô∏è‚É£ Local Docker Commands ‚Äì Testing Before Deployment
docker build -t sanic-api:1.0.0 .
    ‚Ä¢ Build an image from the current directory (.)
    ‚Ä¢ Tag it as sanic-api:1.0.0
        ‚ó¶ sanic-api is name
        ‚ó¶ 1.0.0 is version tag

docker run -d -p 8000:8000 --name sanic-api sanic-api:1.0.0
    ‚Ä¢ -d ‚Üí run in background (detached)
    ‚Ä¢ -p 8000:8000 ‚Üí map:
        ‚ó¶ host port 8000 ‚Üí container port 8000
    ‚Ä¢ --name sanic-api ‚Üí easy name to manage container
    ‚Ä¢ sanic-api:1.0.0 ‚Üí image to run

curl http://localhost:8000
curl http://localhost:8000/health
    ‚Ä¢ Hit the app through Docker port mapping and check responses.
    ‚Ä¢ If this works ‚Üí your Dockerization is correct.

5Ô∏è‚É£ Git & GitHub Commands ‚Äì Version Control & Remote Repo
git init
    ‚Ä¢ Start a Git repository in the folder.
git add .
git commit -m "Initial commit - Sanic API with Docker"
    ‚Ä¢ git add . ‚Üí stage all files.
    ‚Ä¢ git commit ‚Üí save a snapshot.
git branch -M main
    ‚Ä¢ Ensure the main branch is called main.
git remote add origin https://github.com/GIRISH-15/sanic-api.git
git push -u origin main
    ‚Ä¢ remote add origin ‚Üí connect local repo to GitHub repo.
    ‚Ä¢ git push ‚Üí send code to GitHub.
Why?
CI/CD tools (GitHub Actions) watch this repo and trigger pipelines on push.

6Ô∏è‚É£ EC2 Setup Commands
On EC2:
sudo dnf update -y
    ‚Ä¢ Updates system packages to latest (similar to apt update && upgrade).
sudo dnf install docker -y
    ‚Ä¢ Installs Docker engine on EC2.
sudo systemctl start docker
    ‚Ä¢ Start Docker service.
sudo usermod -aG docker ec2-user
    ‚Ä¢ Adds ec2-user to docker group so you can run docker without sudo.
Why?
EC2 becomes a machine that can pull Docker images and run containers.

7Ô∏è‚É£ deploy_sanic.sh ‚Äì Deployment Script on EC2
File: ~/deploy/deploy_sanic.sh
#!/bin/bash
set -e
    ‚Ä¢ #!/bin/bash ‚Üí tells the system this is a bash script.
    ‚Ä¢ set -e ‚Üí exit script if any command fails. Prevents silent errors.

IMAGE="girishsatya/sanic-api:latest"
CONTAINER="sanic-api"
    ‚Ä¢ Two variables:
        ‚ó¶ IMAGE = name of the Docker image to deploy
        ‚ó¶ CONTAINER = Docker container name to use
Makes it easy to change later if needed.

docker pull $IMAGE
    ‚Ä¢ Pulls the latest version of the image from DockerHub.

docker rm -f $CONTAINER || true
    ‚Ä¢ Remove any existing container with same name:
        ‚ó¶ docker rm -f ‚Üí forcibly stop & remove
        ‚ó¶ || true ‚Üí if container doesn‚Äôt exist, don‚Äôt fail the script

docker run -d --name $CONTAINER -p 8000:8000 $IMAGE
    ‚Ä¢ Run the new container using:
        ‚ó¶ name = sanic-api
        ‚ó¶ port map = host 8000 ‚Üí container 8000
        ‚ó¶ image from DockerHub

docker ps
    ‚Ä¢ List running containers to verify deployment.
Why script?
So GitHub Actions (or you manually) can deploy with a single command, instead of typing multiple docker commands.

8Ô∏è‚É£ GitHub Secrets ‚Äì Secure Configuration
You stored these values:
    ‚Ä¢ DOCKERHUB_USERNAME ‚Üí Docker Hub login username
    ‚Ä¢ DOCKERHUB_TOKEN ‚Üí Docker Hub access token (instead of plain password)
    ‚Ä¢ EC2_HOST ‚Üí e.g. 3.110.219.214
    ‚Ä¢ EC2_USER ‚Üí ec2-user
    ‚Ä¢ EC2_SSH_KEY ‚Üí private key for SSH to EC2
Why secrets?
    ‚Ä¢ YAML workflow is public in repo; secrets must not be hard-coded.
    ‚Ä¢ GitHub secrets hide them and inject them securely at runtime.

9Ô∏è‚É£ GitHub Actions Workflow ‚Äì CI/CD Logic
File: .github/workflows/ci-cd.yml
Header
name: CI-CD Sanic API
    ‚Ä¢ Human-readable name for the workflow.
on:
  push:
    branches: ["main"]
    ‚Ä¢ Trigger: whenever code is pushed to main branch.

Job Definition
jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    ‚Ä¢ Defines a job named build-and-deploy.
    ‚Ä¢ Runs on a GitHub-hosted Ubuntu Linux VM.

Step 1 ‚Äì Checkout Code
    steps:
    - uses: actions/checkout@v4
    ‚Ä¢ Clones your repo into the runner.
    ‚Ä¢ Without this, there is no code to build.

Step 2 ‚Äì Setup Docker Buildx
    - uses: docker/setup-buildx-action@v3
    ‚Ä¢ Prepares Docker Buildx, which supports advanced builds.
    ‚Ä¢ Often needed for docker/build-push-action.

Step 3 ‚Äì Login to Docker Hub
    - uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}
    ‚Ä¢ Logs into DockerHub from the GitHub runner.
    ‚Ä¢ Uses secrets, not plaintext.
    ‚Ä¢ Required to push images.

Step 4 ‚Äì Build & Push Docker Image
    - uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: |
          girishsatya/sanic-api:latest
    ‚Ä¢ context: . ‚Üí build from repo root (where Dockerfile is).
    ‚Ä¢ push: true ‚Üí push the built image to Docker Hub.
    ‚Ä¢ tags: ... ‚Üí image name and tag.
Result:
New image available at docker.io/girishsatya/sanic-api:latest

Step 5 ‚Äì Deploy to EC2 via SSH
    - uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_SSH_KEY }}
        script: |
          chmod +x ~/deploy/deploy_sanic.sh
          ~/deploy/deploy_sanic.sh
    ‚Ä¢ appleboy/ssh-action ‚Üí GitHub Action that can SSH into a server.
    ‚Ä¢ Uses:
        ‚ó¶ host = EC2 IP
        ‚ó¶ username = ec2-user
        ‚ó¶ key = private key
    ‚Ä¢ script: | ‚Üí commands that will run on the EC2 machine:
      chmod +x ~/deploy/deploy_sanic.sh
      ~/deploy/deploy_sanic.sh
What happens on EC2:
    1. Make sure script is executable
    2. Run script ‚Üí pulls latest image ‚Üí stops old container ‚Üí runs new container
Why this whole workflow?
This is the heart of CI/CD:
    ‚Ä¢ CI: Build & push image on every commit.
    ‚Ä¢ CD: Automatically deploy new version to EC2.

üîü Phase 8 ‚Äì Testing CI/CD
git commit -am "Updated message"
git push
    ‚Ä¢ Any change to app.py (like changing the "message")
triggers the entire pipeline:
    1. GitHub Actions triggers on push
    2. Builds new image
    3. Pushes to Docker Hub
    4. SSH to EC2
    5. Runs new container
Then you verify with:
http://<EC2_PUBLIC_IP>:8000/
http://<EC2_PUBLIC_IP>:8000/health
If the message changed, it proves that:
    ‚Ä¢ New code ‚Üí new image ‚Üí new container on EC2, automatically.
That‚Äôs full CI/CD working. ‚úÖ

